{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjynC5I5qwdMWZiiV+utyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louisdennington-design/decision-tree-dissertation/blob/main/llm_makes_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AE9TItDTttR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd65fdd-0bbf-4fad-c294-60b9bd48a660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "tpxWJWQBwyad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set base parameters\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "LOAD_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/Scrapes\"\n",
        "LOAD_FILE = os.path.join(LOAD_PATH, \"guideline_raw.json\")\n",
        "\n",
        "SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/JSON\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "SAVE_FILE = os.path.join(SAVE_PATH, \"guideline_structured.json\")"
      ],
      "metadata": {
        "id": "tO5o8yykwzaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLM\n",
        "\n",
        "\"\"\"\n",
        "Focus should be on instruction-following models from Hugging Face\n",
        "With free licence (Apache)\n",
        "Qwen seems to have been trained on producing JSON formats\n",
        "...allows for many tokens as input\n",
        "...parameters are good balance between small and big\n",
        "Should also check Llama offerings?\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\")"
      ],
      "metadata": {
        "id": "wzBIc0pGrsre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "## Should also carry out test prompt of transforming recommendations\n",
        "\n",
        "text = \"Should someone with a diagnosis of bipolar who is taking lithium be referred to secondary care if they are mildly irritable?\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "L13yt0E5NlfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON of raw recommendations\n",
        "\n",
        "def load_json():\n",
        "    try:\n",
        "        with open(LOAD_FILE, \"r\", encoding=\"utf-8\") as raw_recommendations:\n",
        "            return json.load(raw_recommendations)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f'JSON file not found: {LOAD_FILE}')\n",
        "\n",
        "raw_recommendations = load_json()\n",
        "\n",
        "print(type(raw_recommendations))\n",
        "print(len(raw_recommendations))\n",
        "print(raw_recommendations[0])"
      ],
      "metadata": {
        "id": "TMTjqJSd6IT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_prompt(entity):\n",
        "\n",
        "    \"\"\"\n",
        "    Given one recommendation entry {}, creates the prompt to extract one normalised JSON item\n",
        "    \"\"\"\n",
        "\n",
        "    heading_1 = entity.get('heading_1')\n",
        "    sub_heading_1 = entity.get('sub_heading_1')\n",
        "    sub_heading_2 = entity.get('sub_heading_2')\n",
        "\n",
        "    original_recommendation_number = entity.get('original_recommendation_number')\n",
        "    original_recommendation_text = entity.get('original_recommendation_text')\n",
        "\n",
        "    heading_context = \" > \".join(h.strip() for h in [heading_1, sub_heading_1, sub_heading_2] if isinstance(h, str) and h.strip())\n",
        "\n",
        "    return f\"\"\"\n",
        "    You are extracting structured information from a NICE guideline recommendation.\n",
        "\n",
        "    RULES:\n",
        "    - output must be valid JSON only (no markdown)\n",
        "    - do not invent clinical information, thresholds or populations; use only what is present\n",
        "    - 'action' is a concrete imperative\n",
        "    - if there is more than one action, retain all\n",
        "    - 'conditionality' is determined by clauses that begin 'if...' or 'where...'\n",
        "    - 'prohibitions' are 'do not', 'must not' and 'should not'\n",
        "    - record urgency as 'True' if the text includes 'urgent', 'urgently', 'immediate' or 'immediately'\n",
        "    - you MUST use 'null' if the information is not explicit in the recommendation or heading\n",
        "\n",
        "    CONTEXT: {heading_context}\n",
        "\n",
        "    RECOMMENDATION NUMBER: {original_recommendation_number}\n",
        "    RECOMMENDATION TEXT: {original_recommendation_text}\n",
        "\n",
        "    Produce JSON with exactly these keys:\n",
        "    - action\n",
        "    - scope\n",
        "    - population\n",
        "    - conditionality\n",
        "    - prohibitions\n",
        "    - urgency\n",
        "    - original_recommendation_number\n",
        "    - original_recommendation_text\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "LPfVqWLjwkp1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm_on_entity(tokenizer, model, entity):\n",
        "\n",
        "    \"\"\"\n",
        "    Call the model on a single prompt using the prompt function\n",
        "    Return model response\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = construct_prompt(entity)\n",
        "\n",
        "    inputs = tokenizer(prompt,\n",
        "                       return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(**inputs,\n",
        "                             max_new_tokens=500,\n",
        "                             do_sample=False) # deterministic decoding without random sampling\n",
        "                                            # if removed, reinstate temperature / top_p / top_k\n",
        "\n",
        "    llm_response = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[1]:],\n",
        "                                          skip_special_tokens=True)\n",
        "\n",
        "    return llm_response[0]"
      ],
      "metadata": {
        "id": "g4i10M6L6HUM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_output_to_true_json(llm_response):\n",
        "    \"\"\"\n",
        "    Takes output from run_llm_on_entity\n",
        "    Turns it into a true JSON dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = llm_response.strip()\n",
        "\n",
        "    start = llm_response.find(\"{\")\n",
        "    end = llm_response.rfind(\"}\")\n",
        "\n",
        "    if start == -1 or end == -1 or end < start: # Where -1 is \"not found\" for str.find()\n",
        "        raise ValueError(\"Could not find a JSON object in the LLM output.\")\n",
        "\n",
        "    json_string = llm_response[start:end + 1].strip()\n",
        "\n",
        "    try:\n",
        "        json_object = json.loads(json_string)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parsing error: {e}\")\n",
        "        raise\n",
        "\n",
        "    if not isinstance(json_object, dict):\n",
        "        raise TypeError(f\"The object created by the function convert_output_to_true_json is not a JSON object. Instead it is a {type(json_object)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "6JNEcneM4_9y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_json(json_object, required_keys):\n",
        "\n",
        "    missing_keys = [k for k in required_keys if k not in json_object]\n",
        "    if missing_keys:\n",
        "        raise ValueError(f\"Missing required keys: {missing_keys}\")\n",
        "\n",
        "    extra_keys = [k for k in json_object.keys() if k not in required_keys]\n",
        "    if extra_keys:\n",
        "        raise ValueError(f\"Unexpected extra keys: {extra_keys}\")\n",
        "\n",
        "    for key, value in json_object.items():\n",
        "        if value is None:\n",
        "            continue\n",
        "        if key == \"urgency\" and isinstance(value, bool):\n",
        "            continue\n",
        "        if isinstance(value, str):\n",
        "            continue\n",
        "        raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "lrr2NrRwS4Px"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate_create_json(raw_recommendations, tokenizer, model, save_file):\n",
        "\n",
        "    compiled_recommendations = []\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    required_keys = [\"action\",\n",
        "                    \"scope\",\n",
        "                    \"population\",\n",
        "                    \"conditionality\",\n",
        "                    \"prohibitions\",\n",
        "                    \"urgency\",\n",
        "                    \"original_recommendation_number\",\n",
        "                    \"original_recommendation_text\"]\n",
        "\n",
        "    for i, entity in enumerate(raw_recommendations):\n",
        "\n",
        "        llm_output_text = run_llm_on_entity(tokenizer, model, entity)\n",
        "\n",
        "        try:\n",
        "            parsed_json = convert_output_to_true_json(llm_output_text)\n",
        "            validate_json(parsed_json, required_keys)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error {e} at point {i}\")\n",
        "            errors.append({\"index\": i, \"error\": str(e), \"raw_llm_output\": llm_output_text})\n",
        "            continue\n",
        "\n",
        "        compiled_recommendations.append(parsed_json)\n",
        "\n",
        "    with open(save_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(compiled_recommendations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Here is the list of json parsing errors: {errors}\")\n",
        "\n",
        "    return compiled_recommendations, errors"
      ],
      "metadata": {
        "id": "ywpViS98UaMo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrate_create_json(raw_recommendations, tokenizer, model, SAVE_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP954QoS9gIY",
        "outputId": "e84bbb48-e376-4bec-e283-2ad5f96c1f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON parsing error: Expecting value: line 7 column 20 (char 345)\n",
            "Error Expecting value: line 7 column 20 (char 345) at point 8\n",
            "JSON parsing error: Extra data: line 11 column 1 (char 661)\n",
            "Error Extra data: line 11 column 1 (char 661) at point 9\n",
            "Error Key 'action' is of the wrong type, namely: <class 'list'>. at point 12\n",
            "Error Key 'action' is of the wrong type, namely: <class 'list'>. at point 13\n",
            "JSON parsing error: Extra data: line 12 column 5 (char 518)\n",
            "Error Extra data: line 12 column 5 (char 518) at point 18\n"
          ]
        }
      ]
    }
  ]
}