{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "H100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMOtqcLNT/i9Y/P7o49HV3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louisdennington-design/decision-tree-dissertation/blob/main/llm_makes_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AE9TItDTttR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4962a0-043a-427a-b03d-a1df402ddd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "\n",
        "import os\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "tpxWJWQBwyad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set base parameters\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "LOAD_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/Scrapes\"\n",
        "LOAD_FILE = os.path.join(LOAD_PATH, \"guideline_raw.json\")\n",
        "\n",
        "SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/JSON\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "SAVE_FILE = os.path.join(SAVE_PATH, \"guideline_structured.json\")\n",
        "\n",
        "# Error path and file name are defined below in orchestrate function to allow time-stamp"
      ],
      "metadata": {
        "id": "tO5o8yykwzaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\")"
      ],
      "metadata": {
        "id": "wzBIc0pGrsre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU connection\n",
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(model.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imTU61VH5xpD",
        "outputId": "12927de3-42ac-444d-8f7f-4b8322cc19db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "## Should also carry out test prompt of transforming recommendations?\n",
        "\n",
        "text = \"Should someone with a diagnosis of bipolar who is taking lithium be referred to secondary care if they are mildly irritable?\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "L13yt0E5NlfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cbafb6-a695-44ce-f7e4-4aab86ccb2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should someone with a diagnosis of bipolar who is taking lithium be referred to secondary care if they are mildly irritable? No, not necessarily. Lithium is a mood stabilizer commonly used in the treatment of bipolar disorder, and it can help manage symptoms such as mania, hypomania, depression, and irritability. Mild irritability alone does not typically warrant a referral to secondary care.\n",
            "\n",
            "However, it's important to monitor the individual's overall mental health status and any changes in their condition. If the irritability persists or worsens, or if there are other concerning symptoms (such as significant mood swings, suicidal thoughts, psychotic features, or side effects from the medication), then a referral to secondary care might be appropriate for a more comprehensive evaluation and management plan.\n",
            "\n",
            "Regular follow-ups with a primary care provider or a psychiatrist are crucial to ensure that the treatment plan is effective and safe. They can adjust the medication dosage, add or change medications, or provide additional interventions as needed.\n",
            "\n",
            "If you're unsure about the next steps, it's always best to consult with the individual's healthcare provider for personalized advice based on their specific circumstances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON of raw recommendations\n",
        "\n",
        "def load_json(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f'JSON file not found: {file_path}')\n",
        "\n",
        "raw_recommendations = load_json(LOAD_FILE)\n",
        "\n",
        "print(type(raw_recommendations))\n",
        "print(len(raw_recommendations))\n",
        "print(raw_recommendations[0])"
      ],
      "metadata": {
        "id": "TMTjqJSd6IT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce85bc44-33fd-4903-f62e-370370c108c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "136\n",
            "{'heading_1': '1.1 Care for adults, children and young people across all phases of bipolar disorder', 'sub_heading_1': 'Treatment and support for specific populations', 'sub_heading_2': None, 'original_recommendation_number': '1.1.1', 'original_recommendation_text': 'Ensure that older people with bipolar disorder are offered the same range of treatments and services as younger people with bipolar disorder.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Old version: trying to separate out all conditions\n",
        "\n",
        "def construct_prompt(entity):\n",
        "\n",
        "    # Need to do manual read-through of entire guideline to check value fidelity\n",
        "    # Risk: maybe risk_to_others hasn't been populated at all, is that correct?\n",
        "    # Work on physical health fields to increase specificity?\n",
        "    # current_manic_phase is only populating occasionally with \"mania\" and not other values: incorrect?\n",
        "\n",
        "    \"\"\"\n",
        "    Given one recommendation entry {}, creates the prompt to extract one normalised JSON item\n",
        "    \"\"\"\n",
        "\n",
        "    heading_1 = entity.get('heading_1')\n",
        "    sub_heading_1 = entity.get('sub_heading_1')\n",
        "    sub_heading_2 = entity.get('sub_heading_2')\n",
        "\n",
        "    original_recommendation_number = entity.get('original_recommendation_number')\n",
        "    original_recommendation_text = entity.get('original_recommendation_text')\n",
        "\n",
        "    heading_context = \" > \".join(h.strip() for h in [heading_1, sub_heading_1, sub_heading_2] if isinstance(h, str) and h.strip())\n",
        "\n",
        "    return f\"\"\"\n",
        "    You are extracting structured information from a NICE guideline recommendation.\n",
        "\n",
        "    RULES:\n",
        "    - output must be valid JSON ONLY (no markdown; no commentary)\n",
        "    - do not invent clinical information, thresholds or populations; use only what is present in the recommendation text\n",
        "    - For ALL clinical descriptor fields (e.g. phase, severity, medication): populate a value ONLY if it is explicitly stated in the recommendation text. Do NOT infer information that is not directly stated. If not explicit, use null.\n",
        "    - 'conditionality' must be a string describing the constraint or constraints on the implementation of a recommended clinical action, indicated by clauses such as 'if...', 'where...', 'when...' or 'who are...' (e.g., 'if a person has rapid or excessive weight gain, abnormal lipid levels or problems with blood glucose management'). If the text says ‘If [condition], do X’, conditionality must include the entire [condition] clause (including outcomes like response/no response), even if it contains time windows. Do not treat time windows (“within 4 weeks…”, “after 4–6 weeks…”) as conditionality unless they are part of an if/when trigger. If none is mentioned, record null. If multiple conditions, return each as a string in a list. Do not include recommendation 'action' content, which occurs at the boundary before the action verb.\n",
        "    - 'conditionality_type' must be one of: ['temporal_trigger', 'prohibition', 'treatment_stage', 'prescribed_medication', 'side_effects', 'treatment_response', 'test_results', 'patient_preference', null]. If more than one applies, record all as a list of strings. 'prescribed_medication' applies only if the person is currently taking a named medication. 'treatment_stage' indicates start/stop/change/adjust/monitor language.\n",
        "    - 'conditionality_operator' must show how multiple conditionality items are logically combined. It must be 'and' if all conditions apply, or 'or' if one condition is sufficient. If only one condition is present or 'conditionality' is null, record null. If the structure is mixed or unclear, record 'undetermined'.\n",
        "    - 'action' must be a verb phrase indicating the clinical decision or intervention (e.g., 'continue treatment and care in an early intervention in psychosis service, a specialist bipolar disorder service or a specialist integrated community-based team', monitor closely for signs of depression...) that is being done to/for a person. It should capture the clinical instruction and not merely the verb (e.g., 'ensure that people have access to calming environments and reduced stimulation', not just 'ensure'). If more than one action is mentioned, retain all as a list of strings. When an action includes a quantitative target (dose, plasma level, frequency, duration), include that target in the action string. Do NOT include information giving (indicated by 'explain', 'discuss' or similar verbs): This should be stored in 'information_giving'. Do not include if/when information relevant to conditionality.\n",
        "    - 'information_giving' must be a verb phrase indicating sharing information, explaining or discussing with the patient. If not mentioned, set to null.\n",
        "    - 'temporal_constraints' must capture additional requirements attached to an action, such as timing, frequency, duration or review intervals that affects an action (e.g., 'within 4 weeks of symptom resolution', 'for a trial period of 6 months'). If no temporal_constraints are mentioned, record null.\n",
        "    - Extract 'prohibitions_and_cautions' from verb phrases including 'do not', 'must not' or 'should not', and clauses beginning 'but...'. If none are mentioned, record null.\n",
        "    - 'population' is the patient or staff group that the recommendation applies to (e.g., 'people with bipolar…', 'pregnant women…', 'psychological therapists', etc.). If none is mentioned, record null.\n",
        "    - 'age_group' must be one of: ['child', 'young_person', 'older_adult', 'adult', null]\n",
        "    - Extract 'urgency' as True if the text includes 'urgent', 'urgently', 'immediate' or 'immediately', otherwise False\n",
        "    - 'manic_episode_history' must be one of: ['none', 'one', 'multiple', null]\n",
        "    - 'current_manic_phase' must be one of: ['mania', 'hypomania', 'depression', 'mixed', 'rapid_cycling', 'euthymic', null]\n",
        "    - 'symptom_severity' must be one of: ['mild', 'moderate', 'severe', null]\n",
        "    - 'current_psychosis' must be one of: ['present', 'absent', null]\n",
        "    - 'diagnoses' must be one or more mental health diagnoses. If more than one diagnosis is mentioned, record all as a list of strings. If none are mentioned, record null.\n",
        "    - 'prescribed_medication' should be populated by medication names if the recommendation states explicitly that the patient is taking them currently, or that the recommendation only applies to patients who are taking a medication. Otherwise set it to null and record any medications in 'suggested_medications'. If there are multiple medication names, retain each as a list of strings.\n",
        "    - 'medication_adherence' must be one of: ['good', 'poor', null]\n",
        "    - 'side_effects' is a string describing side effects mentioned in the recommendation, or is set to null.\n",
        "    - 'suggested_treatment' should be populated by suggested treatment actions (medication names, psychological therapies, exercise programmes, electroconvulsive therapy), or set to null. If there are treatments suggested, retain each as a list of strings. If the medications are to be taken together (as suggested by 'combined'), record as a single string.\n",
        "    - 'treatment_stage' must be one of: ['start', 'stop', 'continue', 'change', 'adjust', 'monitor', null]\n",
        "    - 'psychological_therapy_type' must be one of: ['psychodynamic', 'psychoeducation', 'cognitive_behavioural', 'other', null]\n",
        "    - 'psychological_therapy_delivery' must be one of: ['individual', 'group', null]\n",
        "    - 'attitude_towards_psychological_therapy' must be one of: ['positive', 'ambivalent', 'negative', null]\n",
        "    - 'physical_health_longterm' must be the name of a physical disease diagnosis that usually affects a person for more than six months. If more than one diagnosis is mentioned, record all as a list of strings. If none are mentioned, record null.\n",
        "    - 'physical_health_recent' must be the name of a transient disease (less than six months) or physical health event from the last six months. Treat phrases like ‘impaired renal function’ and ‘raised calcium’ as physical_health_recent/longterm even if not phrased as a formal diagnosis. If more than one diagnosis is mentioned, record all as a list of strings. If none are mentioned, record null.\n",
        "    - 'risk' must be one of: ['self_harm', 'risk_to_others', 'general_risk_planning', null]\n",
        "    - 'clinical_setting' must be one of: ['assessment', 'primary_care', 'secondary_care', 'inpatient', null]\n",
        "    - 'care_coordination' must be one of: ['current', 'offered', null]\n",
        "    - 'treatment_response' must be one of: ['good', 'ineffective', 'poorly_tolerated', 'relapse', null]\n",
        "    - 'test_name' must be the name of a recognised physical health test (e.g., eGFR, urea, creatinine, thyroid). If more than one test is mentioned, record all as a list of strings. If none is mentioned, record null.\n",
        "    - 'test_result_status' must be one of: ['low', 'raised', 'declining', 'abnormal', 'normal', null]\n",
        "    - 'patient_preferences' is a string describing what the patient has requested, refused, or expressed a preference for. If no preference is stated, record null.\n",
        "    - 'advanced_statement_present' must be set to True if the recommendation mentions the possible presence of an official personal plan of care wishes for future crises, False if it is specifically mentioned as absent, or null.\n",
        "\n",
        "    CONTEXT: {heading_context}\n",
        "\n",
        "    RECOMMENDATION NUMBER: {original_recommendation_number}\n",
        "    RECOMMENDATION TEXT: {original_recommendation_text}\n",
        "\n",
        "    Produce JSON with exactly these keys:\n",
        "####################################################################### populate list\n",
        "\n",
        "    REMEMBER:\n",
        "    - you MUST use null if the information for any field is not explicit in the recommendation or heading\n",
        "    - if there is more than one value for any field, retain all as a list of strings\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "LPfVqWLjwkp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New version: restructuring to \"if-then\" distinction\n",
        "\n",
        "def construct_prompt(entity):\n",
        "    \"\"\"\n",
        "    tbc\n",
        "    \"\"\"\n",
        "\n",
        "    heading_1 = entity.get('heading_1')\n",
        "    sub_heading_1 = entity.get('sub_heading_1')\n",
        "    sub_heading_2 = entity.get('sub_heading_2')\n",
        "\n",
        "    original_recommendation_number = entity.get('original_recommendation_number')\n",
        "    original_recommendation_text = entity.get('original_recommendation_text')\n",
        "\n",
        "    heading_context = \" > \".join(h.strip() for h in [heading_1, sub_heading_1, sub_heading_2] if isinstance(h, str) and h.strip())\n",
        "\n",
        "    return f\"\"\"\n",
        "You are extracting information from a NICE guideline recommendation into a structured JSON format.\n",
        "\n",
        "RULES:\n",
        "- Output valid JSON ONLY (no markdown; no commentary)\n",
        "- Do not invent clinical information, thresholds, populations or interpretations.\n",
        "- Prefer phrases that are taken directly from the recommendation text or use only minor rephrasing.\n",
        "- If something is not explicitly stated, use null.\n",
        "- If more than one value applies for a field, retain all values as a list of strings.\n",
        "\n",
        "TASK:\n",
        "From the recommendation, separate:\n",
        "1) 'IF' STATE (condition/triggers): everything that constrains when to carry out a clinical action\n",
        "2) 'THEN' ACTIONS: clinical interventions (assessing, referring, testing, treating, advising, etc.)\n",
        "\n",
        "'IF' STATE:\n",
        "- Capture all explicit triggers/constraints indicated by 'if', 'where', 'for people who...', 'in those who...', 'only if...', etc. (e.g., 'if a person has rapid or excessive weight gain, abnormal lipid levels or problems with blood glucose management')\n",
        "- Each state must be an explicit clause or phrase from the recommendation text (only minor rephasing permitted).\n",
        "- Store the type of each condition as a separate object in if_state.condition[].\n",
        "- Do NOT put action verbs or intervention instructions into conditions.\n",
        "\n",
        "if_state.condition[].category must be one of:\n",
        "- 'population' is a string of the patient or staff group that the recommendation applies to (e.g., 'people with bipolar…', 'pregnant women…', 'psychological therapists', etc.). If none is mentioned, record null.\n",
        "- 'age_group' must be one of ['child','young_person','adult','older_adult', null]\n",
        "- 'sex' must be one of ['female', 'male', 'other', null]\n",
        "- 'pregnancy' must be True, False, or null if not stated.\n",
        "- 'diagnoses' must be one or more mental health diagnoses. If more than one diagnosis is mentioned, record all as a list of strings. If none are mentioned, record null.\n",
        "- 'current_phase' must be one of ['mania','hypomania','depression', 'bipolar_depression', 'mixed','rapid_cycling','euthymic', null]\n",
        "- 'symptom_severity' must be one of ['mild','moderate','severe', null]\n",
        "- 'current_psychosis': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- 'manic_episode_history' must be one of: ['none', 'one', 'multiple', null]\n",
        "- 'temporal_trigger' must be a string describing time-based constraint on the relevance of an if-condition (e.g., 'during pregnancy', 'in the postnatal period', 'within the first month of treatment', 'for at least 6 months'). If none are mentioned, record null.\n",
        "- 'prohibition_trigger' from verb phrases including 'do not', 'must not' or 'should not', and clauses beginning 'but...'. If none are mentioned, record null.\n",
        "- 'prescribed_medication': populate with medication name/names or type/types ONLY if the text explicitly states the person is currently taking the medication\n",
        "- 'treatment_stage' must be one of: ['start', 'stop', 'continue', 'change', 'adjust', 'monitor', 'other', null]\n",
        "- treatment_response_summary: one of ['good','ineffective','poorly_tolerated','relapse', 'other', null]\n",
        "- 'adverse_effect' is a string describing side effects mentioned in the recommendation, or is set to null.\n",
        "- 'medication_adherence': one of ['good','poor', null]\n",
        "- 'attitude_towards_psychological_therapy' must be one of: ['positive', 'ambivalent', 'negative', null]\n",
        "- 'risk_of_selfharm': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- 'risk_of_suicide': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- 'risk_to_other_people': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- 'risk_other_risk_type': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- physical_health_longterm: physical disease/condition usually >6 months IF explicitly stated\n",
        "- 'physical_health_recent': recent/transient condition OR explicit abnormal states like 'impaired renal function' or 'raised calcium'\n",
        "- 'clinical_test_type' must be the name of a recognised physical health test (e.g., eGFR, urea, creatinine, thyroid, etc.).\n",
        "- 'test_result_status' must be one of: ['low', 'raised', 'declining', 'abnormal', 'normal', 'other', null]\n",
        "- clinical_setting: one of ['assessment','primary_care','secondary_care','inpatient', null]\n",
        "- 'care_coordination' must be one of: ['current', 'offered', null]\n",
        "- 'patient_preferences' is a string describing what the patient has requested, refused, or expressed a preference for. If no preference is stated, record null.\n",
        "- 'advanced_statement_present' must be set to True if the recommendation mentions the possible presence of an official personal plan of care wishes for future crises, False if it is specifically mentioned as absent, or null.\n",
        "- 'other'\n",
        "\n",
        "'IF' LOGIC:\n",
        "- if_state.logic describes how the categories combine:\n",
        "  - 'and' if all must hold\n",
        "  - 'or' if any is sufficient\n",
        "  - 'undetermined' if mixed/unclear\n",
        "  - null if there are one or fewer categories\n",
        "- Do not guess if it is not clear from the wording.\n",
        "\n",
        "'THEN' ACTIONS:\n",
        "- Capture each recommended intervention as a separate object in then_actions[].\n",
        "- The action_text should be a verb phrase (e.g., 'measure the person's BMI', 'continue treatment and care in an early intervention in psychosis service, a specialist bipolar disorder service or a specialist integrated community-based team', 'monitor closely for signs of depression...').\n",
        "- Action should capture the clinical instruction and not merely the verb (e.g., 'ensure that people have access to calming environments and reduced stimulation', not just 'ensure').\n",
        "- When an action includes a quantitative target (dose, plasma level, frequency, duration), include that target in the action string.\n",
        "- 'Do not / must not / should not' statements are actions and must be extracted to actions.prohibitions\n",
        "\n",
        "then_actions[].action_type must be one of:\n",
        "- 'information_giving': True if present, False if explicitly negated, or null if not mentioned.\n",
        "- 'suggested_medications': populate medications that are recommended/considered/started/stopped/changed (if not explicitly current). If the medications are to be taken together (as suggested by 'combined'), record as a single string.\n",
        "- 'monitoring_test' must be the name of a recognised physical health test (e.g., eGFR, urea, creatinine, thyroid, etc.) if the action is to carry out a test or monitor a parameter; otherwise null.\n",
        "- 'psychological_therapy_type' must be one of: ['psychodynamic', 'psychoeducation', 'cognitive_behavioural', 'other', null]\n",
        "- 'psychological_therapy_delivery' must be one of: ['individual', 'group', null]\n",
        "- 'onward_referral': True if suggested, False if explicitly negated, or null if not mentioned.\n",
        "- 'care_coordination': True if suggested, False if explicitly negated, or null if not mentioned.\n",
        "- 'risk_management': True if suggested, False if explicitly negated, or null if not mentioned.\n",
        "- 'other_treatment' should be a string describing any other type of treatment action not covered by the above categories (e.g., exercise programme, nutrition, electroconvulsive therapy), or null.\n",
        "- 'urgency': True if 'urgent/urgently/immediate/immediately' present; else False\n",
        "- 'temporal_constraints' must capture additional requirements attached to the action, such as timing, frequency, duration or review intervals that affects an action (e.g., 'within 4 weeks of symptom resolution', 'for a trial period of 6 months'). If no temporal_constraints are mentioned, record null.\n",
        "\n",
        "CONTEXT: {heading_context}\n",
        "\n",
        "RECOMMENDATION NUMBER: {original_recommendation_number}\n",
        "RECOMMENDATION TEXT: {original_recommendation_text}\n",
        "\n",
        "Produce JSON with exactly these keys (and no others):\n",
        "\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "FdpflJ24YwXp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check prompt length\n",
        "\n",
        "recommendation_for_prompt_check = raw_recommendations[24]\n",
        "\n",
        "prompt_test = construct_prompt(recommendation_for_prompt_check)\n",
        "\n",
        "token_count = tokenizer.encode(prompt_test)\n",
        "\n",
        "print(f\"Prompt token length: {len(token_count)}\\n\")\n",
        "\n",
        "print(f\"Recommendation used for prompt check: {recommendation_for_prompt_check}\")"
      ],
      "metadata": {
        "id": "7NtJ_QMiirnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce69999c-27a5-457b-fffb-07e93364a183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt token length: 1448\n",
            "\n",
            "Recommendation used for prompt check: {'heading_1': '1.3 Assessing suspected bipolar disorder in adults in secondary care', 'sub_heading_1': None, 'sub_heading_2': None, 'original_recommendation_number': '1.3.2', 'original_recommendation_text': \"When assessing suspected bipolar disorder:, and undertake a full psychiatric assessment, documenting a detailed history of mood, episodes of overactivity and disinhibition or other episodic and sustained changes in behaviour, symptoms between episodes, triggers to previous episodes and patterns of relapse, and family history, and assess the development and changing nature of the mood disorder and associated clinical problems throughout the person's life (for example, early childhood trauma, developmental disorder or cognitive dysfunction in later life), and assess social and personal functioning and current psychosocial stressors, and assess for potential mental and physical comorbidities, and assess the person's physical health and review medication and side effects, including weight gain, and discuss treatment history and identify interventions that have been effective or ineffective in the past, and encourage people to invite a family member or carer to give a corroborative history, and discuss possible factors associated with changes in mood, including relationships, psychosocial factors and lifestyle changes, and identify personal recovery goals.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm_on_entity(tokenizer, model, entity):\n",
        "\n",
        "    \"\"\"\n",
        "    Call the model on a single prompt using the prompt function\n",
        "    Return model response\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = construct_prompt(entity)\n",
        "\n",
        "    inputs = tokenizer(prompt,\n",
        "                       return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(**inputs,\n",
        "                             max_new_tokens=500,\n",
        "                             do_sample=False) # deterministic decoding without random sampling\n",
        "                                            # if removed, reinstate temperature / top_p / top_k\n",
        "\n",
        "    llm_response = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[1]:],\n",
        "                                          skip_special_tokens=True)\n",
        "\n",
        "    return llm_response[0]"
      ],
      "metadata": {
        "id": "g4i10M6L6HUM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source for nested curly braces extraction: https://til.magmalabs.io/posts/01a278bb48-extracting-json-code-with-nested-curly-braces-in-ruby-the-long-painful-way-around-with-help-from-gpt4"
      ],
      "metadata": {
        "id": "sW9k8rxFKMIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_output_to_true_json(llm_response):\n",
        "    \"\"\"\n",
        "    Takes output from run_llm_on_entity\n",
        "    Turns it into a true JSON dictionary\n",
        "    Checks whether it is a JSON file\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = llm_response.strip()\n",
        "\n",
        "    start = llm_response.find(\"{\")\n",
        "\n",
        "    if start == -1: # Where -1 is not found in .find string method\n",
        "        raise ValueError(\"In converting_output_to_true_json function, no initial { was found in the output from the LLM.\\n\")\n",
        "\n",
        "    brace_count = 0\n",
        "    json_string = None\n",
        "\n",
        "    for i in range(start, len(llm_response)):\n",
        "\n",
        "        if llm_response[i] == \"{\":\n",
        "            brace_count += 1\n",
        "        elif llm_response[i] == \"}\":\n",
        "            brace_count -= 1\n",
        "\n",
        "            if brace_count == 0:\n",
        "\n",
        "                json_string = llm_response[start:i + 1].strip()\n",
        "                break\n",
        "\n",
        "    if json_string is None:\n",
        "        raise ValueError(\"In converting_output_to_true_json function, no closing } was found in the output from the LLM.\\n\")\n",
        "\n",
        "    try:\n",
        "        json_object = json.loads(json_string)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parsing error: {e}\")\n",
        "        raise\n",
        "\n",
        "    if not isinstance(json_object, dict):\n",
        "        raise TypeError(f\"The object created by the function convert_output_to_true_json is not a JSON object. Instead it is a {type(json_object)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "6JNEcneM4_9y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_json(json_object, required_keys):\n",
        "\n",
        "    \"\"\"\n",
        "    Checks the structure of the JSON to see whether it has the required keys\n",
        "    ... and is populated with the right types of data\n",
        "    \"\"\"\n",
        "\n",
        "    missing_keys = [k for k in required_keys if k not in json_object]\n",
        "    if missing_keys:\n",
        "        raise ValueError(f\"Missing required keys: {missing_keys}\")\n",
        "\n",
        "    extra_keys = [k for k in json_object.keys() if k not in required_keys]\n",
        "    if extra_keys:\n",
        "        raise ValueError(f\"Unexpected extra keys: {extra_keys}\")\n",
        "\n",
        "    for key, value in json_object.items():\n",
        "        if value is None:\n",
        "            continue\n",
        "\n",
        "        # Fields with constrained values\n",
        "        if key == 'age_group' and value in {'child','young_person','older_adult','adult'}:\n",
        "            continue\n",
        "        if key == 'clinical_setting' and value in {'assessment', 'primary_care', 'secondary_care', 'inpatient'}:\n",
        "            continue\n",
        "        if key == 'manic_episode_history' and value in {'none', 'one', 'multiple'}:\n",
        "            continue\n",
        "        if key == 'conditionality_operator' and value in {'and', 'or'}:\n",
        "            continue\n",
        "        if key == 'current_manic_phase' and value in {'mania', 'hypomania', 'depression', 'mixed', 'rapid_cycling', 'euthymic'}:\n",
        "            continue\n",
        "        if key == 'symptom_severity' and value in {'mild', 'moderate', 'severe'}:\n",
        "            continue\n",
        "        if key == 'current_psychosis' and value in {'present', 'absent'}:\n",
        "            continue\n",
        "        if key == 'medication_adherence' and value in {'good', 'poor'}:\n",
        "            continue\n",
        "        if key == 'risk' and value in {'self_harm', 'risk_to_others'}:\n",
        "            continue\n",
        "        if key == 'care_coordination' and value in {'current', 'offered'}:\n",
        "            continue\n",
        "\n",
        "        # Boolean fields\n",
        "        if key in {\"urgency\", \"psychological_therapy\"} and isinstance(value, bool):\n",
        "            continue\n",
        "\n",
        "        # String or list of string fields\n",
        "        if isinstance(value, str):\n",
        "            continue\n",
        "\n",
        "        if isinstance(value, list) and all(isinstance(v, str) for v in value):\n",
        "            continue\n",
        "\n",
        "        raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "lrr2NrRwS4Px"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_json(json_object, required_keys):\n",
        "\n",
        "    \"\"\"\n",
        "    Checks the structure of the JSON to see whether it has the required keys\n",
        "    ... and is populated with the right types of data\n",
        "    \"\"\"\n",
        "\n",
        "    missing_keys = [k for k in required_keys if k not in json_object]\n",
        "    if missing_keys:\n",
        "        raise ValueError(f\"Missing required keys: {missing_keys}\")\n",
        "\n",
        "    extra_keys = [k for k in json_object.keys() if k not in required_keys]\n",
        "    if extra_keys:\n",
        "        raise ValueError(f\"Unexpected extra keys: {extra_keys}\")\n",
        "\n",
        "    for key, value in json_object.items():\n",
        "        if value is None:\n",
        "            continue\n",
        "\n",
        "        # Fields with constrained values (new schema)\n",
        "        if key == \"age_group\" and value in {\"child\", \"young_person\", \"older_adult\", \"adult\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"clinical_setting\" and value in {\"assessment\", \"primary_care\", \"secondary_care\", \"inpatient\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"current_manic_phase\" and value in {\"mania\", \"hypomania\", \"depression\", \"mixed\", \"rapid_cycling\", \"euthymic\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"symptom_severity\" and value in {\"mild\", \"moderate\", \"severe\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"current_psychosis\" and value in {\"present\", \"absent\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"medication_adherence\" and value in {\"good\", \"poor\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"risk\" and value in {\"self_harm\", \"risk_to_others\", \"general_risk_planning\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"care_coordination\" and value in {\"current\", \"offered\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"treatment_response_summary\" and value in {\"good\", \"ineffective\", \"poorly_tolerated\", \"relapse\"}:\n",
        "            continue\n",
        "\n",
        "        if key == \"test_result_status\" and value in {\"low\", \"raised\", \"declining\", \"abnormal\", \"normal\"}:\n",
        "            continue\n",
        "\n",
        "        # Structured objects required by new prompt\n",
        "        if key == \"if_state\":\n",
        "            if not isinstance(value, dict):\n",
        "                raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "            if set(value.keys()) != {\"predicates\", \"operator\"}:\n",
        "                raise TypeError(f\"Key '{key}' must have exactly keys: ['predicates', 'operator'].\")\n",
        "            if not isinstance(value[\"predicates\"], list):\n",
        "                raise TypeError(\"if_state.predicates must be a list.\")\n",
        "            for p in value[\"predicates\"]:\n",
        "                if not isinstance(p, dict):\n",
        "                    raise TypeError(\"Each predicate must be an object (dict).\")\n",
        "                if set(p.keys()) != {\"text_span\", \"category\", \"negated\"}:\n",
        "                    raise TypeError(\"Each predicate must have exactly keys: ['text_span','category','negated'].\")\n",
        "                # predicate fields can be null, but if present enforce types/allowed categories\n",
        "                if p[\"text_span\"] is not None and not isinstance(p[\"text_span\"], str):\n",
        "                    raise TypeError(\"predicate.text_span must be a string or null.\")\n",
        "                if p[\"category\"] is not None:\n",
        "                    if not isinstance(p[\"category\"], str):\n",
        "                        raise TypeError(\"predicate.category must be a string or null.\")\n",
        "                    if p[\"category\"] not in {\n",
        "                        \"patient_characteristic\",\n",
        "                        \"treatment_status\",\n",
        "                        \"treatment_response\",\n",
        "                        \"adverse_effect\",\n",
        "                        \"test_result\",\n",
        "                        \"risk\",\n",
        "                        \"setting\",\n",
        "                        \"preference\",\n",
        "                        \"temporal_trigger\",\n",
        "                        \"prohibition_trigger\",\n",
        "                        \"other\",\n",
        "                    }:\n",
        "                        raise TypeError(f\"predicate.category has unexpected value: {p['category']}\")\n",
        "                if p[\"negated\"] is not None and not isinstance(p[\"negated\"], bool):\n",
        "                    raise TypeError(\"predicate.negated must be a bool or null.\")\n",
        "            # operator can be null or one of allowed strings\n",
        "            op = value[\"operator\"]\n",
        "            if op is not None and op not in {\"and\", \"or\", \"undetermined\"}:\n",
        "                raise TypeError(\"if_state.operator must be 'and', 'or', 'undetermined', or null.\")\n",
        "            continue\n",
        "\n",
        "        if key == \"then_actions\":\n",
        "            if not isinstance(value, list):\n",
        "                raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "            for a in value:\n",
        "                if not isinstance(a, dict):\n",
        "                    raise TypeError(\"Each then_actions item must be an object (dict).\")\n",
        "                if set(a.keys()) != {\"action_text\", \"action_type\", \"timing_frequency\", \"prohibitions_cautions\"}:\n",
        "                    raise TypeError(\"Each action must have exactly keys: ['action_text','action_type','timing_frequency','prohibitions_cautions'].\")\n",
        "                if a[\"action_text\"] is not None and not isinstance(a[\"action_text\"], str):\n",
        "                    raise TypeError(\"action.action_text must be a string or null.\")\n",
        "                if a[\"action_type\"] is not None:\n",
        "                    if not isinstance(a[\"action_type\"], str):\n",
        "                        raise TypeError(\"action.action_type must be a string or null.\")\n",
        "                    if a[\"action_type\"] not in {\n",
        "                        \"information_giving\",\n",
        "                        \"medication\",\n",
        "                        \"monitoring_test\",\n",
        "                        \"psychological_therapy\",\n",
        "                        \"referral\",\n",
        "                        \"care_coordination\",\n",
        "                        \"environmental\",\n",
        "                        \"risk_management\",\n",
        "                        \"other\",\n",
        "                    }:\n",
        "                        raise TypeError(f\"action.action_type has unexpected value: {a['action_type']}\")\n",
        "                if a[\"timing_frequency\"] is not None and not isinstance(a[\"timing_frequency\"], str):\n",
        "                    raise TypeError(\"action.timing_frequency must be a string or null.\")\n",
        "                pc = a[\"prohibitions_cautions\"]\n",
        "                if pc is not None:\n",
        "                    if isinstance(pc, str):\n",
        "                        pass\n",
        "                    elif isinstance(pc, list) and all(isinstance(v, str) for v in pc):\n",
        "                        pass\n",
        "                    else:\n",
        "                        raise TypeError(\"action.prohibitions_cautions must be a string, list of strings, or null.\")\n",
        "            continue\n",
        "\n",
        "        # Boolean fields (new schema)\n",
        "        if key in {\"urgency\"} and isinstance(value, bool):\n",
        "            continue\n",
        "\n",
        "        if key == \"advanced_statement_present\":\n",
        "            if isinstance(value, bool) or value is None:\n",
        "                continue\n",
        "            raise TypeError(f\"Key '{key}' must be bool or null.\")\n",
        "\n",
        "        # String or list of string fields (as per prompt)\n",
        "        if isinstance(value, str):\n",
        "            continue\n",
        "\n",
        "        if isinstance(value, list) and all(isinstance(v, str) for v in value):\n",
        "            continue\n",
        "\n",
        "        raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "\n",
        "    return json_object\n"
      ],
      "metadata": {
        "id": "MngqemKEZPZ1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate_create_json(raw_recommendations, tokenizer, model, save_file):\n",
        "\n",
        "    compiled_recommendations = []\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    required_keys = ['heading_context',\n",
        "                    'original_recommendation_number',\n",
        "                    'original_recommendation_text',\n",
        "                    'action',\n",
        "                    'information_giving',\n",
        "                     'temporal_constraints'\n",
        "                    'prohibitions_and_cautions',\n",
        "                    'population',\n",
        "                    'age_group',\n",
        "                    'conditionality',\n",
        "                     'conditionality_operator',\n",
        "                    'urgency',\n",
        "                    'manic_episode_history',\n",
        "                    'current_manic_phase',\n",
        "                    'symptom_severity',\n",
        "                    'current_psychosis',\n",
        "                    'diagnoses',\n",
        "                    'current_medication',\n",
        "                    'suggested_medication',\n",
        "                    'medication_adherence',\n",
        "                    'physical_health_longterm',\n",
        "                    'physical_health_recent',\n",
        "                    'risk',\n",
        "                    'psychological_therapy',\n",
        "                    'other_treatments',\n",
        "                    'clinical_setting',\n",
        "                    'care_coordination']\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for i, entity in enumerate(raw_recommendations): # Add [:] slicing for test runs\n",
        "\n",
        "        llm_output_text = run_llm_on_entity(tokenizer, model, entity)\n",
        "\n",
        "        try:\n",
        "            parsed_json = convert_output_to_true_json(llm_output_text)\n",
        "            validate_json(parsed_json, required_keys)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error {e} at point {i}\")\n",
        "            errors.append({\"index\": i, \"error\": str(e), \"raw_llm_output\": llm_output_text, \"entity\": entity})\n",
        "            continue\n",
        "\n",
        "        compiled_recommendations.append(parsed_json)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "        if counter % 10 == 0: print(f'Number of recommendations processed: {counter}')\n",
        "\n",
        "    with open(save_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(compiled_recommendations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    datetime_now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "    ERROR_SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/JSON/LLM_conversion_errors\"\n",
        "    os.makedirs(ERROR_SAVE_PATH, exist_ok=True)\n",
        "    ERROR_SAVE_FILE = os.path.join(ERROR_SAVE_PATH, f\"llm_conversion_errors_{datetime_now}.json\")\n",
        "\n",
        "    with open(ERROR_SAVE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(errors, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Here is the list of json parsing errors: {errors}\\n\\n\")\n",
        "\n",
        "    return compiled_recommendations, errors"
      ],
      "metadata": {
        "id": "ywpViS98UaMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate_create_json(raw_recommendations, tokenizer, model, save_file):\n",
        "\n",
        "    compiled_recommendations = []\n",
        "    errors = []\n",
        "\n",
        "    # REQUIRED KEYS for the new IF/THEN schema (top-level only)\n",
        "    required_keys = [\n",
        "        \"heading_context\",\n",
        "        \"original_recommendation_number\",\n",
        "        \"original_recommendation_text\",\n",
        "\n",
        "        \"if_state\",\n",
        "        \"then_actions\",\n",
        "\n",
        "        \"population\",\n",
        "        \"urgency\",\n",
        "\n",
        "        \"age_group\",\n",
        "        \"diagnoses\",\n",
        "\n",
        "        \"current_manic_phase\",\n",
        "        \"symptom_severity\",\n",
        "        \"current_psychosis\",\n",
        "\n",
        "        \"clinical_setting\",\n",
        "        \"care_coordination\",\n",
        "\n",
        "        \"prescribed_medication\",\n",
        "        \"suggested_medications\",\n",
        "        \"medication_adherence\",\n",
        "\n",
        "        \"side_effects\",\n",
        "        \"treatment_response_summary\",\n",
        "\n",
        "        \"test_name\",\n",
        "        \"test_result_status\",\n",
        "\n",
        "        \"patient_preferences\",\n",
        "\n",
        "        \"physical_health_longterm\",\n",
        "        \"physical_health_recent\",\n",
        "\n",
        "        \"risk\",\n",
        "        \"advanced_statement_present\",\n",
        "    ]\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for i, entity in enumerate(raw_recommendations):  # Add [:] slicing for test runs\n",
        "        llm_output_text = run_llm_on_entity(tokenizer, model, entity)\n",
        "\n",
        "        try:\n",
        "            parsed_json = convert_output_to_true_json(llm_output_text)\n",
        "            validate_json(parsed_json, required_keys)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error {e} at point {i}\")\n",
        "            errors.append(\n",
        "                {\n",
        "                    \"index\": i,\n",
        "                    \"error\": str(e),\n",
        "                    \"raw_llm_output\": llm_output_text,\n",
        "                    \"entity\": entity,\n",
        "                }\n",
        "            )\n",
        "            continue\n",
        "\n",
        "        compiled_recommendations.append(parsed_json)\n",
        "        counter += 1\n",
        "\n",
        "        if counter % 10 == 0:\n",
        "            print(f\"Number of recommendations processed: {counter}\")\n",
        "\n",
        "    with open(save_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(compiled_recommendations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    datetime_now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    ERROR_SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/JSON/LLM_conversion_errors\"\n",
        "    os.makedirs(ERROR_SAVE_PATH, exist_ok=True)\n",
        "    ERROR_SAVE_FILE = os.path.join(ERROR_SAVE_PATH, f\"llm_conversion_errors_{datetime_now}.json\")\n",
        "\n",
        "    with open(ERROR_SAVE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(errors, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Here is the list of json parsing errors: {errors}\\n\\n\")\n",
        "\n",
        "    return compiled_recommendations, errors\n"
      ],
      "metadata": {
        "id": "z_MyhDVRZDTW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrate_create_json(raw_recommendations, tokenizer, model, SAVE_FILE)"
      ],
      "metadata": {
        "id": "gP954QoS9gIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "37fce2ec-a04f-4e03-e819-8122e128de61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON parsing error: Expecting ',' delimiter: line 3 column 40 (char 199)\n",
            "Error Expecting ',' delimiter: line 3 column 40 (char 199) at point 0\n",
            "JSON parsing error: Expecting ',' delimiter: line 3 column 40 (char 199)\n",
            "Error Expecting ',' delimiter: line 3 column 40 (char 199) at point 1\n",
            "JSON parsing error: Expecting ',' delimiter: line 3 column 40 (char 199)\n",
            "Error Expecting ',' delimiter: line 3 column 40 (char 199) at point 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2413070006.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morchestrate_create_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1960588488.py\u001b[0m in \u001b[0;36morchestrate_create_json\u001b[0;34m(raw_recommendations, tokenizer, model, save_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_recommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Add [:] slicing for test runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mllm_output_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_llm_on_entity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1378945192.py\u001b[0m in \u001b[0;36mrun_llm_on_entity\u001b[0;34m(tokenizer, model, entity)\u001b[0m\n\u001b[1;32m     11\u001b[0m                        return_tensors=\"pt\").to(model.device)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     outputs = model.generate(**inputs,\n\u001b[0m\u001b[1;32m     14\u001b[0m                              \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                              do_sample=False) # deterministic decoding without random sampling\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2787\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2789\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2791\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Fully Connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checked 27/01/2026\n",
        "\n",
        "## LLM output missing\n",
        "\n",
        "1.1.4\n",
        "1.1.5\n",
        "1.1.9\n",
        "1.2.2\n",
        "1.2.5\n",
        "1.3.2\n",
        "1.3.5\n",
        "1.3.7\n",
        "1.4.1\n",
        "1.5.1\n",
        "1.5.2\n",
        "1.5.3\n",
        "1.5.7\n",
        "1.5.10\n",
        "1.6.3\n",
        "1.6.4\n",
        "1.7.1\n",
        "1.7.4\n",
        "1.10.7\n",
        "1.11.8"
      ],
      "metadata": {
        "id": "XI7inll_WeQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}