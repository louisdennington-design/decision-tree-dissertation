{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNhzNX6/VcDv9KhMqtGxks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louisdennington-design/decision-tree-dissertation/blob/main/llm_makes_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AE9TItDTttR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2a4253-3c6d-4e40-fa58-1a999ff0010c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "tpxWJWQBwyad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set base parameters\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "LOAD_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/Scrapes\"\n",
        "LOAD_FILE = os.path.join(LOAD_PATH, \"guideline_raw.json\")\n",
        "\n",
        "SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dissertation/JSON\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "SAVE_FILE = os.path.join(SAVE_PATH, \"guideline_structured.json\")"
      ],
      "metadata": {
        "id": "tO5o8yykwzaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLM\n",
        "\n",
        "\"\"\"\n",
        "Focus should be on instruction-following models from Hugging Face\n",
        "With free licence (Apache)\n",
        "Qwen seems to have been trained on producing JSON formats\n",
        "...allows for many tokens as input (up to 128k!)\n",
        "...parameters are good balance between small and big\n",
        "Should also check Llama offerings?\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\")"
      ],
      "metadata": {
        "id": "wzBIc0pGrsre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "## Should also carry out test prompt of transforming recommendations\n",
        "\n",
        "text = \"Should someone with a diagnosis of bipolar who is taking lithium be referred to secondary care if they are mildly irritable?\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "L13yt0E5NlfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON of raw recommendations\n",
        "\n",
        "def load_json(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f'JSON file not found: {file_path}')\n",
        "\n",
        "raw_recommendations = load_json(LOAD_FILE)\n",
        "\n",
        "print(type(raw_recommendations))\n",
        "print(len(raw_recommendations))\n",
        "print(raw_recommendations[0])"
      ],
      "metadata": {
        "id": "TMTjqJSd6IT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd983c53-b754-480e-9dff-27460f60b82b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "136\n",
            "{'heading_1': '1.1 Care for adults, children and young people across all phases of bipolar disorder', 'sub_heading_1': 'Treatment and support for specific populations', 'sub_heading_2': None, 'original_recommendation_number': '1.1.1', 'original_recommendation_text': 'Ensure that older people with bipolar disorder are offered the same range of treatments and services as younger people with bipolar disorder.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_prompt(entity):\n",
        "\n",
        "    \"\"\"\n",
        "    Given one recommendation entry {}, creates the prompt to extract one normalised JSON item\n",
        "    \"\"\"\n",
        "\n",
        "    heading_1 = entity.get('heading_1')\n",
        "    sub_heading_1 = entity.get('sub_heading_1')\n",
        "    sub_heading_2 = entity.get('sub_heading_2')\n",
        "\n",
        "    original_recommendation_number = entity.get('original_recommendation_number')\n",
        "    original_recommendation_text = entity.get('original_recommendation_text')\n",
        "\n",
        "    heading_context = \" > \".join(h.strip() for h in [heading_1, sub_heading_1, sub_heading_2] if isinstance(h, str) and h.strip())\n",
        "\n",
        "    return f\"\"\"\n",
        "    You are extracting structured information from a NICE guideline recommendation.\n",
        "\n",
        "    RULES:\n",
        "    - output must be valid JSON ONLY (no markdown; no commentary)\n",
        "    - do not invent clinical information, thresholds or populations; use only what is present in the recommendation text\n",
        "    - For ALL clinical descriptor fields (e.g. phase, severity, medication): populate a value ONLY if it is explicitly stated in the recommendation text. Do NOT infer information that is not directly stated. If not explicit, use null.\n",
        "    - 'action' must be a verb phrase indicating what is being done and to/for whom (e.g., 'ensure that people have access to calming environments and reduced stimulation', not just 'ensure')\n",
        "    - 'scope' must be the setting/service/context (e.g., 'in primary care', 'in secondary care', 'in a service that can…', 'when assessing…')\n",
        "    - 'population' is the group the recommendation applies to (e.g., 'people with…', 'older people…', 'adults…', 'children…', 'pregnant women…', etc.)\n",
        "    - Extract 'conditionality' from clauses that begin 'if...' or 'where...'\n",
        "    - Extract 'prohibitions' from verb phrases including 'do not', 'must not' or 'should not'\n",
        "    - Extract 'urgency' as 'True' if the text includes 'urgent', 'urgently', 'immediate' or 'immediately', otherwise 'False'\n",
        "    - 'manic_episode_history' must be one of: ['none', 'one', 'multiple', null]\n",
        "    - 'current_manic_phase' must be one of: ['mania', 'hypomania', 'bipolar_depression', 'mixed', 'rapid_cycling', 'euthymic', null]\n",
        "    - 'mania_severity' must be one of: ['mild', 'moderate', 'severe', null]\n",
        "    - 'current_psychosis' must be: ['present', 'absent', null]\n",
        "    - 'diagnoses' must be one or more comorbid mental health diagnoses. If more than one diagnosis is mentioned, record all as a list of strings.\n",
        "    - 'current_medication' must be a medication name or null\n",
        "    - 'medication_adherence' must be one of: ['good', 'poor', null]\n",
        "    - 'physical_health_longterm' must be the name of a physical disease diagnosis that affects a person for more than six months. If more than one diagnosis is mentioned, record all as a list of strings.\n",
        "    - 'physical_health_recent' must be the name of a transient disease (less than six months) or physical health event from the last six months. If more than one diagnosis is mentioned, record all as a list of strings.\n",
        "    - 'risk' must be one of: ['self_harm', 'risk_to_others', null]\n",
        "    - 'psychological_therapy' must be one of: ['offered', null]\n",
        "    - 'care_coordination' must be one of: ['current', 'offered', null]\n",
        "    - you MUST use 'null' if the information for any field is not explicit in the recommendation or heading\n",
        "    - if there is more than one value for any field, retain all as a list of strings\n",
        "\n",
        "    CONTEXT: {heading_context}\n",
        "\n",
        "    RECOMMENDATION NUMBER: {original_recommendation_number}\n",
        "    RECOMMENDATION TEXT: {original_recommendation_text}\n",
        "\n",
        "    Produce JSON with exactly these keys:\n",
        "    - action\n",
        "    - scope\n",
        "    - population\n",
        "    - conditionality\n",
        "    - prohibitions\n",
        "    - urgency\n",
        "    - manic_episode_history\n",
        "    - current_manic_phase\n",
        "    - mania_severity\n",
        "    - current_psychosis\n",
        "    - diagnoses\n",
        "    - current_medication\n",
        "    - medication_adherence\n",
        "    - physical_health_longterm\n",
        "    - physical_health_recent\n",
        "    - risk\n",
        "    - psychological_therapy\n",
        "    - care_coordination\n",
        "    - heading_context\n",
        "    - original_recommendation_number\n",
        "    - original_recommendation_text\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "LPfVqWLjwkp1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check prompt length\n",
        "\n",
        "recommendation_for_prompt_check = raw_recommendations[24]\n",
        "\n",
        "prompt_test = construct_prompt(recommendation_for_prompt_check)\n",
        "\n",
        "token_count = tokenizer.encode(prompt_test)\n",
        "\n",
        "print(f\"Prompt token length: {len(token_count)}\\n\")\n",
        "\n",
        "print(f\"Recommendation used for prompt check: {recommendation_for_prompt_check}\")"
      ],
      "metadata": {
        "id": "7NtJ_QMiirnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83824a0c-738d-4af2-cf13-887a2e583e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt token length: 962\n",
            "\n",
            "Recommendation used for prompt check: {'heading_1': '1.3 Assessing suspected bipolar disorder in adults in secondary care', 'sub_heading_1': None, 'sub_heading_2': '[2014]', 'original_recommendation_number': '1.3.2', 'original_recommendation_text': \"When assessing suspected bipolar disorder: undertake a full psychiatric assessment, documenting a detailed history of mood, episodes of overactivity and disinhibition or other episodic and sustained changes in behaviour, symptoms between episodes, triggers to previous episodes and patterns of relapse, and family history, and assess the development and changing nature of the mood disorder and associated clinical problems throughout the person's life (for example, early childhood trauma, developmental disorder or cognitive dysfunction in later life), and assess social and personal functioning and current psychosocial stressors, and assess for potential mental and physical comorbidities, and assess the person's physical health and review medication and side effects, including weight gain, and discuss treatment history and identify interventions that have been effective or ineffective in the past, and encourage people to invite a family member or carer to give a corroborative history, and discuss possible factors associated with changes in mood, including relationships, psychosocial factors and lifestyle changes, and identify personal recovery goals. \"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm_on_entity(tokenizer, model, entity):\n",
        "\n",
        "    \"\"\"\n",
        "    Call the model on a single prompt using the prompt function\n",
        "    Return model response\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = construct_prompt(entity)\n",
        "\n",
        "    inputs = tokenizer(prompt,\n",
        "                       return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(**inputs,\n",
        "                             max_new_tokens=500,\n",
        "                             do_sample=False) # deterministic decoding without random sampling\n",
        "                                            # if removed, reinstate temperature / top_p / top_k\n",
        "\n",
        "    llm_response = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[1]:],\n",
        "                                          skip_special_tokens=True)\n",
        "\n",
        "    return llm_response[0]"
      ],
      "metadata": {
        "id": "g4i10M6L6HUM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nested curly braces extraction: https://til.magmalabs.io/posts/01a278bb48-extracting-json-code-with-nested-curly-braces-in-ruby-the-long-painful-way-around-with-help-from-gpt4"
      ],
      "metadata": {
        "id": "sW9k8rxFKMIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_output_to_true_json(llm_response):\n",
        "    \"\"\"\n",
        "    Takes output from run_llm_on_entity\n",
        "    Turns it into a true JSON dictionary\n",
        "    Checks whether it is a JSON file\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = llm_response.strip()\n",
        "\n",
        "    start = llm_response.find(\"{\")\n",
        "\n",
        "    if start == -1: # Where -1 is not found in .find string method\n",
        "        raise ValueError(\"In converting_output_to_true_json function, no initial { was found in the output from the LLM.\\n\")\n",
        "\n",
        "    brace_count = 0\n",
        "    json_string = None\n",
        "\n",
        "    for i in range(start, len(llm_response)):\n",
        "\n",
        "        if llm_response[i] == \"{\":\n",
        "            brace_count += 1\n",
        "        elif llm_response[i] == \"}\":\n",
        "            brace_count -= 1\n",
        "\n",
        "            if brace_count == 0:\n",
        "\n",
        "                json_string = llm_response[start:i + 1].strip()\n",
        "                break\n",
        "\n",
        "    if json_string is None:\n",
        "        raise ValueError(\"In converting_output_to_true_json function, no closing } was found in the output from the LLM.\\n\")\n",
        "\n",
        "    try:\n",
        "        json_object = json.loads(json_string)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parsing error: {e}\")\n",
        "        raise\n",
        "\n",
        "    if not isinstance(json_object, dict):\n",
        "        raise TypeError(f\"The object created by the function convert_output_to_true_json is not a JSON object. Instead it is a {type(json_object)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "6JNEcneM4_9y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_json(json_object, required_keys):\n",
        "\n",
        "    \"\"\"\n",
        "    Checks the structure of the JSON to see whether it has the required keys\n",
        "    ... and is populated with the right types of data\n",
        "    \"\"\"\n",
        "\n",
        "    # Needs adjustments once the final structure of the JSON is decided on\n",
        "    # But avoid adapting until this is known\n",
        "\n",
        "    missing_keys = [k for k in required_keys if k not in json_object]\n",
        "    if missing_keys:\n",
        "        raise ValueError(f\"Missing required keys: {missing_keys}\")\n",
        "\n",
        "    extra_keys = [k for k in json_object.keys() if k not in required_keys]\n",
        "    if extra_keys:\n",
        "        raise ValueError(f\"Unexpected extra keys: {extra_keys}\")\n",
        "\n",
        "    for key, value in json_object.items():\n",
        "        if value is None:\n",
        "            continue\n",
        "        if key == \"urgency\" and isinstance(value, bool):\n",
        "            continue\n",
        "        if isinstance(value, str) or isinstance(value, list):\n",
        "            continue\n",
        "        raise TypeError(f\"Key '{key}' is of the wrong type, namely: {type(value)}.\")\n",
        "\n",
        "    return json_object"
      ],
      "metadata": {
        "id": "lrr2NrRwS4Px"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate_create_json(raw_recommendations, tokenizer, model, save_file):\n",
        "\n",
        "    compiled_recommendations = []\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    required_keys = ['action',\n",
        "                    'scope',\n",
        "                    'population',\n",
        "                    'conditionality',\n",
        "                    'prohibitions',\n",
        "                    'urgency',\n",
        "                    'manic_episode_history',\n",
        "                    'current_manic_phase',\n",
        "                    'mania_severity',\n",
        "                    'current_psychosis',\n",
        "                    'diagnoses',\n",
        "                    'current_medication',\n",
        "                    'medication_adherence',\n",
        "                    'physical_health_longterm',\n",
        "                    'physical_health_recent',\n",
        "                    'risk',\n",
        "                    'psychological_therapy',\n",
        "                    'care_coordination',\n",
        "                    'heading_context',\n",
        "                    'original_recommendation_number',\n",
        "                    'original_recommendation_text']\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for i, entity in enumerate(raw_recommendations[:]): # Remove index numbers to process full batch\n",
        "\n",
        "        llm_output_text = run_llm_on_entity(tokenizer, model, entity)\n",
        "\n",
        "        try:\n",
        "            parsed_json = convert_output_to_true_json(llm_output_text)\n",
        "            validate_json(parsed_json, required_keys)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error {e} at point {i}\")\n",
        "            errors.append({\"index\": i, \"error\": str(e), \"raw_llm_output\": llm_output_text})\n",
        "            continue\n",
        "\n",
        "        compiled_recommendations.append(parsed_json)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "        print(f'Number of recommendations processed: {counter}')\n",
        "\n",
        "    with open(save_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(compiled_recommendations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Here is the list of json parsing errors: {errors}\\n\\n\")\n",
        "\n",
        "    return compiled_recommendations, errors"
      ],
      "metadata": {
        "id": "ywpViS98UaMo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrate_create_json(raw_recommendations, tokenizer, model, SAVE_FILE)"
      ],
      "metadata": {
        "id": "gP954QoS9gIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8255cd2-02af-4706-906d-73e59737474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of recommendations processed: 1\n",
            "Number of recommendations processed: 2\n",
            "Number of recommendations processed: 3\n",
            "Number of recommendations processed: 4\n",
            "Number of recommendations processed: 5\n",
            "Number of recommendations processed: 6\n",
            "Number of recommendations processed: 7\n",
            "Number of recommendations processed: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For checking what caused specific JSON parsing errors\n",
        "\n",
        "parsing_error_line = 23\n",
        "parsing_error_column = str(1)\n",
        "parsing_error_character = 728\n",
        "\n",
        "guideline_structured_error_location = load_json(SAVE_FILE)\n",
        "\n",
        "slice_ = guideline_structured_error_location[parsing_error_line][parsing_error_column]\n",
        "exact_character = slice_[728]\n",
        "\n",
        "print(f\"The offending entry: {slice_}\\n\")\n",
        "print(f\"The offending character: {exact_character}\")"
      ],
      "metadata": {
        "id": "52S3oDfRALJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}